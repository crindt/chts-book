---
title: "4.4 Weights for Long-Distance Trips"
author: "Suman Mitra"
date: "September 2, 2015"
output: html_document
---

```{r ldw-setup-0,echo=FALSE,cache=TRUE}
if ( !exists("rd") ) { rd <<- gsub("(.*?chts-book[^/]*).*$","\\1",getwd()) } 
source(paste(rd,"R/setup-hooks.R",sep="/"))
write(paste("Using Root Directory",rd,"\n"),stderr())
```


# Overview 

This document explains how county-level weights are developed for long
distance trips using the R statistical software for people who
participated in the 2012 CHTS. The purpose of these weights is to
scale up information provided by respondents to the population of each
county based on the socio-economic variables listed below. The person
level weights are generated for long distance trips at county
level. Long distance travel file did not properly identify the person
identification number. So we have to rely on variable `LNINI1` (person
who made the trip) and there are 1310 missing observations. Users of
these weights are cautioned that these weights should not be applied
to lower-level geographies such as cities or zip codes. Similar
weights can be developed for these geographies if they contain enough
CHTS respondents.

# Methodology

County wide Weights for Long distance trips are calculated by raking
at the person level. These weights adjust the relative importance of
responses to reflect the different probabilities of selecting
respondents, and align the sample distributions to population
distributions based on the 2010 Census. In particular, long distance
person-level weights were adjusted so that the sum of these weights
equals known population totals for certain subgroups of the population
of each county. Variables used for raking at the person level are:

  * Hispanic Status (Hispanic, Non-Hispanic) - County-wide distribution;
  * Ethnicity (White, African American, Asian, Other) - County-wide distribution;
  * Age (less than 20 years, 20 - 24 years, 25 - 34 years, 35 - 54 years, 55 - 64 years, 65 years or older) - County -wide distribution;
  * Employment Status (Part-time or full-time Employed, Not-employed)- County-wide distribution; and
  * Gender (Male, Female)- County-wide distribution

After the raking procedure, very large weights are capped to be no
more than five times the mean of weight.

\ifmydocumentation

# R Code and Implementation

The following commands are used to generate county wide weights for
long distance trips.

First we need to import the person data frame and corresponding lookup
frame (containing location information) and then we merge them.

```{r ldw-2,cache=TRUE}
# Set the working directory
setwd(pd("Weight/PersonWeight_County"))

library(chts2011)
persondata <- chts_per
library(chts2011pvt)
lookup_hh <- chts_lu_hh

# Merging two data sets to get the county information
perdata2<-merge(persondata,lookup_hh, by ="SAMPN", all = TRUE)
# Names of the new merged file
names(perdata2)
```

Now we have new merged file which is used to generate new person
weight. We need to recode the raking variables to make them similar to
the census data (Here we are using American Community Survey, 2010
five year estimate data).

First we will assign zero for `NA` observations of raking variables
because the code we will use later for raking can't read `NA`.

```{r ldw-3,cache=TRUE}
# Assign 0 for all NA observations
perdata2$HISP[is.na(perdata2$HISP)] <- 0
perdata2$AGE[is.na(perdata2$AGE)] <- 0
perdata2$RACE1[is.na(perdata2$RACE1)] <- 0
perdata2$EMPLY[is.na(perdata2$EMPLY)] <- 0
```

Then, we change the value of the Hispanic variable to make it similar
to census data.

```{r ldw-4,cache=TRUE}
# For changing values of Hispanic
perdata2$HISPn<-ifelse(perdata2$HISP>2,2,perdata2$HISP)

# Show values
head(perdata2$HISPn,10)
```

Next, we recode the age and race variable.

```{r ldw-5,cache=TRUE}
# For recoding AGE
perdata2$AGEn <-
  ifelse(perdata2$AGE<20,1,
         ifelse((perdata2$AGE>=20 & perdata2$AGE<=24),2,
                ifelse((perdata2$AGE>=25 & perdata2$AGE<=34),3,
                       ifelse((perdata2$AGE>=35 & perdata2$AGE<=54),4,
                              ifelse((perdata2$AGE>=55 & perdata2$AGE<=64),5,6)))))
# Show values
head(perdata2$AGE,10)

# For recoding race
perdata2$RACEn <-
  ifelse(perdata2$RACE1==1,1,
         ifelse(perdata2$RACE1==2,2,
                ifelse(perdata2$RACE1==4,3,4)))

# Show values
head(perdata2$RACEn,10)
```


Here, we recode the employment (`EMPLY`) and Gender (`GEND`) variables.

```{r ldw-6,cache=TRUE}
# For recoding EMPLY
perdata2$EMPLYn <-
  ifelse(perdata2$EMPLY==1,1,
         ifelse(perdata2$EMPLY==2,2,
                ifelse(perdata2$EMPLY==8,1,2)))

# Show values
head(perdata2$EMPLYn,10)

# For recoding Gender
perdata2$GENDn<-ifelse(perdata2$GEND==1,1,2)
# Show the data
head(perdata2$GENDn,10)
```

Now we have data frame (`perdata2`) which has coding similar to the
census data for raking variables.  We need county wide total
population data which we collect from census and save it as csv (we
organize them as per our requirement). Here we import that file and
merge this data with `perdata2`.


```{r ldw-7,cache=TRUE}
# Assign county wide total population into perdata2 file
# Import the countywise total population csv file and give a new name
tot.pop <- read.csv(pd("Weight/Data_County/Total/county_totpop2.csv"),
                    header=TRUE)
head(tot.pop)

# Merging two data set
perdata3<-merge(perdata2,tot.pop, by ="HCTFIP", all = TRUE)
names(perdata3)
```

So, now we have a new file named perdata3 which contains all the
raking variables information and county wide total population.

Now, We need to import the long distance file and corresponding look
up file (containing location information) and merge them.

```{r ldw-8,cache=TRUE}
setwd(pd("Weight/LD_Weight2"))
LD_data <- chts_ld
lookup_LD <- chts_lu_ld

# Dimension of the data file
dim(LD_data)
dim(lookup_LD)

# Check the names of the variables
names(LD_data)
names(lookup_LD)

#Merging two data set
LD_data1<-merge(LD_data,lookup_LD, by =c("SAMPN", "LDNO"), all = TRUE)

# Dimension of the data file
dim(LD_data)
dim(lookup_LD)
dim(LD_data1)

#Names of the variables in the new dataset
names(LD_data1)
```

Here, we delete the duplicate variables and give new names of the
added variables.

```{r ldw-9,cache=TRUE}
# Subset the dataset (excluding the duplicate variables)
nLD_data<-subset(LD_data1,select=-c(6,8,10,11,13,15,17,18,47,48,52,54))
# show the existing variable names 
names(nLD_data)
#rename the added variables
names(nLD_data) [c(44:52,55,58,59)] <-
  c("LDOCITY","LDOZIP","LDOXCORD","LDOYCORD","LDDCITY","LDDZIP",
    "LDDXCORD","LDDYCORD","LDOCTFIP","LDDCTFIP","LDOPrimaryCity",
    "LDDPrimaryCity")
```

There is no person id information in long distance file. But we need
person id to generate person level weight. So we generate a person id
variable from the variable person who made trip (`LDINI1`).

```{r ldw-10,cache=TRUE}
# Create a variable for person id no.
nLD_data$PERNO = nLD_data$LDINI1
head(nLD_data$PERNO)
```

Now, we need to merge the person data with long distance data.

```{r ldw-11,cache=TRUE}
# Merge the person data and long distance data
LD_dataw<-merge(nLD_data,perdata3, by =c("SAMPN", "PERNO"), all = TRUE)
names(LD_dataw)
```

In this data set there are observations for persons who did not take
the long distance trip. We exclude those observations.

```{r ldw-12,cache=TRUE}
# Creat subset 
LD_dataw1<-subset(LD_dataw,!(is.na(LDNO)))
dim(LD_dataw1)
dim(nLD_data)
```

We want to save the file as CSV.

```{r ldw-13,cache=TRUE}
setwd(pd("Weight/LD_Weight2"))
write.csv(LD_dataw1, file="nLD_dataw1.csv", row.names=FALSE)
```

This new merged file contains all county level information. But we
need a single dataframe for each county. So we need to create a list
of separate dataframe for each county.

```{r ldw-14,cache=TRUE}
# create list of dataframes for different counties 
ldcnty_list <- split(LD_dataw1, as.factor(LD_dataw1$HCTFIP))
# Show the list of one county
head(ldcnty_list[[11]])
```

We need census data of raking variables (Hispanic, Race, Employment
status, Gender and Age). We collect this information from census and
organize them as per our requirement and save as CSV file. Then we
import them and create separate dataframe for each county (the CSV
file contains information on all the counties).

First, we do it for Hispanic data.

```{r ldw-15,cache=TRUE}
# Hispanic data
hisp.county <- read.csv(pd("Weight/Data_County/Hispanic/Hisp_county.csv"),
                        header=TRUE)
head(hisp.county)

# Generate a list of seperate datafrmaes containing hispanic data for each county
hisp.county$id <- 1:nrow(hisp.county)
hisp.data <- lapply(
  split(hisp.county, hisp.county$id),
  function(x){
    data.frame(HISPn = c(1,2),
               Freq  = c(x$Hispanic, x$Non.Hispanic))                                                           
  }
)
# Show
head(hisp.data[1])
```

Here, we import the race data.

```{r ldw-16,cache=TRUE}
# Race
race.county <- read.csv(pd("Weight/Data_County/Race/Race_county.csv"),
                        header=TRUE)
race.county$id <- 1:nrow(race.county)
race.data <- lapply(
  split(race.county, race.county$id),
  function(x){
    data.frame(RACEn = c(1:4),
               Freq  = c(x$White, x$African.American,x$Asian,x$Others))                                                             
  }
)
head(race.data[1])
```

Then, we repeat the process for employment data.

```{r ldw-17,cache=TRUE}
## Employment data
emply.county <- read.csv(pd("Weight/Data_County/Employment/Employment_county.csv"),
                         header=TRUE)
emply.county$id <- 1:nrow(emply.county)
emply.data <- lapply(
  split(emply.county, emply.county$id),
  function(x){
    data.frame(EMPLYn = c(1,2),
               Freq  = c(x$Employed, x$Unemployed))                                                             
  }
)
head(emply.data[1])
```

Finally, we import gender and age data.

```{r ldw-18,cache=TRUE}
#Gender
gend.county <- read.csv(pd("Weight/Data_County/Gender/Gender_county.csv"),
                        header=TRUE)
gend.county$id <- 1:nrow(gend.county)
gend.data <- lapply(
  split(gend.county, gend.county$id),
  function(x){
    data.frame(GENDn = c(1,2),  Freq  = c(x$Male, x$Female))
  }
)
head(gend.data[1])

# Age
age.county <- read.csv(pd("Weight/Data_County/Age/Age_county.csv"),
                       header=TRUE)
head(age.county)
age.county$id <- 1:nrow(age.county)
age.data <- lapply(
  split(age.county, age.county$id),
  function(x){
    data.frame(AGEn = c(1:6),
               Freq  = c(x$x1, x$x2,x$x3,x$x4,x$x5,x$x6))
  }
)
head(age.data[48])
```

Here we want to set the directory where we want to save our output.

```{r ldw-19,cache=TRUE}
# Set directory where we want to save
setwd(pd("Weight/LD_Weight2"))
```


As our data is ready for raking, we proceed for raking next. We do it
in a for loop function which generate weight for each county. To do
this we need to install the library `survey`. First we design a survey
using 'svydesign' command and we use sampling without replacement (pps
="brewer") option. Since sampling information is not available for
long distance data, we assume equal probability here. So we don't need
to specify the fpc option here.

Then we perform the raking. After raking, we trim the weight so that
very large weights were capped to be no more than five times the mean
of weight.  The following code also gives us information about the
errors (the FIP code of counties for which the weight can't be
generated). The generated expanded person weights for different
counties are saved in our specified directory.


```{r ldw-20,cache=TRUE}
# Raking for all county to create new expanded weight
#Need library "survey"
library(survey)
# Loop function for raking
# NOTE: length must be equal to 58=total number of county
for (i in 1:length(hisp.data)){ 
  tryCatch({
    # If there is any error it will give error message but still
    # continue the loop 
    f=seq(6001, 6115, by=2)
    s<-as.character(f[i])
    name=paste('LDweight_',s, '.CSV',sep="")
    name=pd(paste("Weight/LD_Weight",name,sep="/"))

    # Survey design with equal probability
    temp1<- svydesign(id=~1,data=ldcnty_list[[i]],pps="brewer") 

    # Raking
    temp3<- rake(temp1, list(~RACEn,~HISPn,~AGEn,~EMPLYn,~GENDn),
                 list(race.data[[i]],hisp.data[[i]],age.data[[i]],
                      emply.data[[i]],gend.data[[i]]),
                 control = list(maxit = 100)) 

    # Trim the weights (max value no greater than 5 times the mean)
    temp4<-trimWeights(temp3,
                       lower=(min(weights(temp3))),
                       upper=(5*mean(weights(temp3))))

    # Combine weight with sample no and person no
    temp5<-cbind(temp4$variables[1:3],weights(temp4))

    # change the column name of weight variable
    colnames(temp5)[4] <- "EXPLDWGT" 

    # Save as csv file
    write.table(temp5, file =name,sep=",", row.names=FALSE, col.names=TRUE) 

  }, error=function(e){
    # Show the errors and the file names
    cat("ERROR :",conditionMessage(e), "\n",finally=print(name))
  }) 
}
```

After running the code, we get twenty four errors for twenty four
counties and we need to treat them individually
(`HCTFIP={3,15,21,27,49,51,91,103,105}`). The errors show that some race
categories are absent from sample of these counties, so we don't
include race as raking variable for these counties in the following
codes.

```{r ldw-21,cache=TRUE}
# Loop function for the rest of the counties
# only for counties which gave error for previous cases
# (HCTFIP=3(i=2);HCTFIP=15(i=8);HCTFIP=21(i=11) and so on)
d=c(2,3,5,6,8,9,11,12,14,17,18,22,23,25,26,35,44,46,47,51,52,53,55,58) 
for (i in d){ 
  tryCatch({
    f=seq(6001, 6115, by=2)
    s<-as.character(f[i])
    name=paste('LDweight_',s, '.CSV',sep="")
    name=pd(paste("Weight/LD_Weight",name,sep="/"))

    # Survey design with equal probability
    temp1<- svydesign(id=~1,data=ldcnty_list[[i]], pps="brewer") 

    # Raking
    temp3<- rake(temp1, list(~HISPn,~EMPLYn,~GENDn),
                 list(hisp.data[[i]],emply.data[[i]],gend.data[[i]]),
                 control = list(maxit = 100)) 

    # Trim the weights (max value no greater than 5 times the mean)
    temp4<-trimWeights(temp3,
                       lower=(min(weights(temp3))),
                       upper=(5*mean(weights(temp3)))) 

    # Combine weight with sample no and person no
    temp5<-cbind(temp4$variables[1:3],weights(temp4)) 

    # change the column name of weight variable
    colnames(temp5)[4] <- "EXPLDWGT" 

    # Save as csv file
    write.table(temp5, file =name,sep=",", row.names=FALSE, col.names=TRUE) 
  }, error=function(e){
    # Show the errors and the file names
    cat("ERROR :",conditionMessage(e), "\n",finally=print(name))
  })
}
```

There are no errors now. So, we have expanded person weights for long
distance trips for all 58 counties and these weights are saved in the
directory we specified earlier. We need to combine these weights of 58
counties into one file. The following codes are used to import and
combine them.


```{r ldw-22,cache=TRUE}
# Import multiple csv file of new expanded weight and combine into one file
setwd(pd("Weight/LD_Weight"))
filenames <- list.files(path = pd("Weight/LD_Weight")) # import the files
# combine the files into one
nldweight2<-do.call("rbind", lapply(filenames, read.csv, header = TRUE)) 
head(nldweight2)
dim(nldweight2)
```

Now, we save the new file as CSV format.

```{r ldw-23,cache=TRUE}
setwd(pd("Weight/LD_Weight2"))
write.csv(nldweight2, file="nldweight922015.csv",row.names = FALSE) 
```

We want to merge the new weight with long distance data file.

```{r ldw-24,cache=TRUE}
# Merge the new weight file with original long distance data file
wLDdata<-merge(nLD_data,nldweight2, by =c("SAMPN","PERNO","LDNO"), all = TRUE)
dim(nLD_data)
dim(nldweight2)
dim(wLDdata)
head(wLDdata)
```

Now we have a long distance data file with new county wide weight and
we want to save it as CSV.

```{r ldw-25,cache=TRUE}
write.csv(wLDdata,
          file=pd(paste("Weight/LD_Weight2","wLD_data922015.csv",sep="/")),
          row.names=FALSE)
```

\fi
